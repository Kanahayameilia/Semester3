{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6def42-446a-4bbc-a7ee-15cbd9102888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "       Name    Age   Salary\n",
      "0    Alice  24.00  48000.0\n",
      "1      Bob  30.00  57000.0\n",
      "2  Charlie  27.75  57000.0\n",
      "3    David  22.00  57000.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Identifying and Handling Missing Data\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', None],\n",
    "    'Age': [24, 30, None, 22, 35],\n",
    "    'Salary': [48000, None, 57000, None, 60000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filling missing values and dropping rows\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].median())\n",
    "df.dropna(subset=['Name'], inplace=True)\n",
    "print('After cleaning:\\n', df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cefa30a-9195-4ec9-9340-d44a2f1a76bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Data:\n",
      "    Product     Category\n",
      "0   Laptop  Electronics\n",
      "1   Laptop  Electronics\n",
      "2  Desktop  Electronics\n",
      "3   Tablet      Gadgets\n",
      "4   Tablet      Gadgets\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Standardizing Categorical Data\n",
    "# Sample dataset with inconsistent categorical values\n",
    "data = {\n",
    "    'Product': ['Laptop', 'Laptop', 'Desktop', 'Tablet', 'Tablet'],\n",
    "    'Category': ['Electronics', 'electronics', 'Electronics', 'Gadgets', 'gadgets']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardize category values\n",
    "df['Category'] = df['Category'].str.capitalize()\n",
    "print('Standardized Data:\\n', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354b285b-f46a-493e-bbdf-b96aad0d84dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/anaconda/.cache/kagglehub/datasets/yasserh/titanic-dataset/versions/1\n",
      "Files in dataset folder: ['Titanic-Dataset.csv']\n",
      "Missing values in each column:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"Files in dataset folder:\", os.listdir(path))\n",
    "\n",
    "# Load the dataset correctly\n",
    "df = pd.read_csv(path + \"/Titanic-Dataset.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d728801-20c2-4b1a-9708-23606920b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /home/anaconda/anaconda3/lib/python3.13/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /home/anaconda/anaconda3/lib/python3.13/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/anaconda/anaconda3/lib/python3.13/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/anaconda/anaconda3/lib/python3.13/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anaconda/anaconda3/lib/python3.13/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anaconda/anaconda3/lib/python3.13/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anaconda/anaconda3/lib/python3.13/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anaconda/anaconda3/lib/python3.13/site-packages (from requests->kagglehub) (2025.10.5)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76fc3d3-4021-494e-b1bc-c60a9f98a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized numerical columns:\n",
      "    PassengerId  Survived  Pclass       Age  SibSp  Parch      Fare\n",
      "0     0.000000       0.0     1.0  0.271174  0.125    0.0  0.014151\n",
      "1     0.001124       1.0     0.0  0.472229  0.125    0.0  0.139136\n",
      "2     0.002247       1.0     1.0  0.321438  0.000    0.0  0.015469\n",
      "3     0.003371       1.0     0.0  0.434531  0.125    0.0  0.103644\n",
      "4     0.004494       0.0     1.0  0.434531  0.000    0.0  0.015713\n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical columns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only numerical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Create the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(\"Normalized numerical columns:\\n\", df[num_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81192282-62c3-43d0-833d-fb37a35f9dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized categorical columns and removed duplicates.\n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0     0.000000       0.0     1.0   \n",
      "1     0.001124       1.0     0.0   \n",
      "2     0.002247       1.0     1.0   \n",
      "3     0.003371       1.0     0.0   \n",
      "4     0.004494       0.0     1.0   \n",
      "\n",
      "                                                Name     Sex       Age  SibSp  \\\n",
      "0                            braund, mr. owen harris    male  0.271174  0.125   \n",
      "1  cumings, mrs. john bradley (florence briggs th...  female  0.472229  0.125   \n",
      "2                             heikkinen, miss. laina  female  0.321438  0.000   \n",
      "3       futrelle, mrs. jacques heath (lily may peel)  female  0.434531  0.125   \n",
      "4                           allen, mr. william henry    male  0.434531  0.000   \n",
      "\n",
      "   Parch            Ticket      Fare Cabin Embarked  \n",
      "0    0.0         a/5 21171  0.014151   NaN        s  \n",
      "1    0.0          pc 17599  0.139136   c85        c  \n",
      "2    0.0  ston/o2. 3101282  0.015469   NaN        s  \n",
      "3    0.0            113803  0.103644  c123        s  \n",
      "4    0.0            373450  0.015713   NaN        s  \n"
     ]
    }
   ],
   "source": [
    "# Standardize categorical columns and remove duplicates\n",
    "\n",
    "# Select only object (categorical) columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Make all categorical data lowercase (standardized)\n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.str.lower())\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Standardized categorical columns and removed duplicates.\\n\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a799406-5e2e-48f8-ad3b-7108d3022ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
